{"type":"data","nodes":[{"type":"data","data":[{"awards":1,"committee":37,"education":45,"experiences":68,"mentoring":115,"news":116,"people":163,"press":365,"publications":393,"reviewer":857,"skills":115,"socialLinkInfo":902,"socialLinks":944,"talks":950,"teaching":1017},[2,6,10,14,18,21,25,29,33],{"name":3,"description":4,"date":5},"Best Poster Award","Energy Transformer receives 2nd placeðŸ¥ˆ in GATech's annual Graduate Poster Symposium","Mar. 2024",{"name":7,"description":8,"date":9},"Best Paper Award, Honorable Mention","DiffusionDB receives a Best Paper, Honorable Mention Award at ACL 2023","July 2023",{"name":11,"description":12,"date":13},"Spotlight Paper Award","HAMUX is spotlighted (top 5 submissions) at the Deep Learning and Differential Equation Workshop at NeurIPS 2022","Dec. 2022",{"name":15,"description":16,"date":17},"Highlighted Reviewer","ICLR 2022","Apr. 2022",{"name":3,"description":19,"date":20},"RXNMapper wins Best Poster award at #IOPPoster 2020","July 2020",{"name":22,"description":23,"date":24},"Best Demo Award","LMdiff is Best Demo at NeurIPS 2020","Dec. 2020",{"name":26,"description":27,"date":28},"(Runner Up) Best Demo","exBERT is runner up for Best Demo at NeurIPS 2019","Dec. 2019",{"name":30,"description":31,"date":32},"Dean's List","In the highest one third of engineering class by GPA at Duke","2013-2017",{"name":34,"description":35,"date":36},"Raul Buelvas Award","Given to one freshman at Duke University who \"best exemplifies honor, optimism, and selflessness\" as voted by peers and faculty","Apr. 2014",[38],{"venue":39,"venueShorthand":40,"years":41},"Associative Memory & Hopfield Network Workshop","AMHN@NeurIPS",[42],{"year":43,"url":44},2023,"https://amhn.vizhub.ai/2023",[46,57,64],{"degree":47,"institution":48,"location":49,"date":50,"description":51,"advisors":52,"institutionUrl":56},"Machine Learning PhD Student","Georgia Tech","Atlanta, GA","Aug 2021 - Present","Studying how to interpret AI Foundation Models through the lens of Associative Memory",[53],{"name":54,"url":55},"Duen Horng (Polo) Chau","https://faculty.cc.gatech.edu/~dchau/","https://www.gatech.edu/",{"degree":58,"institution":59,"location":60,"date":61,"description":62,"institutionUrl":63},"Master of Engineering: Electrical and Computer Engineering","Duke University","Durham, NC","May 2018","Emphasis on Big Data and Signal Processing","https://www.duke.edu/",{"degree":65,"institution":59,"location":60,"date":66,"description":67,"institutionUrl":63},"Bachelor of Science in Engineering: Biomedical Engineering","May 2017","Magna Cum Laude &#x2022; Emphasis on Neurobiology and Imaging",[69,82,93,104],{"institution":70,"institutionUrl":71,"location":72,"role":73,"team":74,"teamUrl":75,"date":76,"type":77,"description":78,"mentors":79},"IBM Research","https://www.research.ibm.com/artificial-intelligence/","Cambridge, MA","Research Engineer","Visual AI Lab","https://researcher.watson.ibm.com/researcher/view_group.php?id=5948","Sep '18 - Present","industry","Member of the \u003Ca href=\"https://researcher.ibm.com/researcher/view_group.php?id=5948\">Visual AI Lab\u003C/a> where we use visualization to breathe insight and interactivity into powerful AI systems.",[80,81],"Hendrik Strobelt","Dmitry Krotov",{"institution":83,"institutionUrl":84,"location":85,"role":86,"team":87,"date":88,"type":77,"description":89,"mentors":90},"Medtronic Diabetes","https://www.medtronicdiabetes.com/home","Northridge, CA","Research Intern","Algorithms R&D","Summer '17","Analyze trends in patient blood glucose levels for the sensor R&D team, developing algorithms that were incorporated into product by the end of the summer.",[91,92],"Peter Ajemba","Keith Nogueira",{"institution":94,"institutionUrl":95,"location":49,"role":96,"team":97,"teamUrl":98,"date":99,"type":100,"description":101,"mentors":102},"Georgia Institute of Technology","http://gatech.edu/","Ph.D. Researcher","Polo Club at School of Computational Science and Engineering","https://poloclub.github.io/","Aug '21 - present","academic","Member of the Polo Club of Data Science where we innovate scalable, interactive, and interpretable tools that amplify human's ability to understand and interact with billion-scale data and machine learning models.",[103],"Polo Chau",{"institution":105,"institutionUrl":106,"location":60,"role":107,"team":108,"teamUrl":109,"date":110,"type":100,"description":111,"mentors":112},"International Genetically Engineered Machine (iGEM)","http://2016.igem.org/","Undergrad Research Assistant","Lynch Lab","https://lynchlabduke.com/","Apr '15 - May '17","Designed experiments to analyze CRISPR-Cas9 binding effects in bacteria, using machine learning to discover patterns in the data.",[113,114],"Eirik Adim Moreb","Michael D. Lynch",null,[117,120,123,126,129,132,135,138,141,143,145,147,150,152,154,157,160],{"date":118,"HTMLdescription":119},"Aug 2024","\u003Cspan style=\"display: flex; justify-content: start; align-items: center; gap: 0.2rem;\">  \u003Cspan style=\"margin-right: 0.5rem\">ðŸš€ \u003Ca href=\"https://poloclub.github.io/transformer-explainer/\">Transformer Explainer\u003C/a> is going viral! \u003C/span> (\n  \u003Ca href=\"https://star-history.com/#poloclub/transformer-explainer&Date\"> \u003Cspan class=\"iconify\" data-icon=\"mdi-github\"/> \u003C/a> \n  \u003Ca href=\"https://x.com/omarsar0/status/1821986172215742716\">\u003Cspan class=\"iconify\" data-icon=\"pajamas-twitter\"/>\u003C/a> \n  \u003Ca href=\"https://huggingface.co/papers/2408.04619\">\u003Cspan class=\"iconify\" data-icon=\"logos-hugging-face-icon\"/>\u003C/a> \n  \u003Ca href=\"https://www.linkedin.com/feed/update/urn:li:activity:7227528635111354368/\">\u003Cspan class=\"iconify\" data-icon=\"mdi-linkedin\"/>\u003C/a>\n  )\n\u003C/span>",{"date":121,"HTMLdescription":122},"Jul 2024","ðŸŽ‰ \u003Ca href=\"https://poloclub.github.io/transformer-explainer/\">Transformer Explainer\u003C/a> accepted as a \u003Ca href=\"https://ieeevis.org/year/2024/welcome\">VIS'24 Poster\u003C/a>!",{"date":124,"HTMLdescription":125},"Jun 2024","ðŸŽ‰ \u003Ca href=\"https://poloclub.github.io/diffusion-explainer/\">Diffusion Explainer\u003C/a> accepted as a \u003Ca href=\"https://ieeevis.org/year/2024/welcome\">VIS'24 Short Paper\u003C/a>!",{"date":127,"HTMLdescription":128},"May 2024","â˜•ï¸ Invited to speak at \u003Ca href=\"https://x.com/plecticslab\">Plectics Lab's\u003C/a> Colloquium: \"Hopfield Networks 2.0: Associative Memory for the Modern Era of AI\" (recorded presentation \u003Ca href=\"https://www.youtube.com/watch?v=8LGRQfaG3ro\">here\u003C/a>)",{"date":130,"HTMLdescription":131},"Apr 2024","ðŸŽ‰ \u003Ca href=\"https://poloclub.github.io/diffusion-explainer/\">Diffusion Explainer\u003C/a> accepted to the Demo Track at \u003Ca href=\"https://ijcai24.org/\">IJCAI 2024\u003C/a>!",{"date":133,"HTMLdescription":134},"Feb 2024","ðŸŽ¬ NeurIPS'23 Associative Memory \u003Ca href=\"https://slideslive.com/neurips-2023/ws-associative-memory-hopfield-networks-in-2023\">workshop recordings\u003C/a> are openly available! See the recorded panel on software engineering and Hopfield Nets \u003Ca href=\"https://slideslive.com/39014683/hopfield-networks-meet-software-engineering?ref=folder-130081\">here\u003C/a> (courtesy of SlidesLive).",{"date":136,"HTMLdescription":137},"Oct 2023","ðŸŽ‰ \u003Ca href=\"https://arxiv.org/abs/2309.16750\">Memory in Plain Sight\u003C/a> and \u003Ca href=\"https://arxiv.org/abs/2302.07253\">Energy Transformer\u003C/a> accepted to \u003Ca href=\"https://amhn.vizhub.ai/\">AMHN Workshop\u003C/a> at NeurIPS 2023!",{"date":139,"HTMLdescription":140},"Sep 2023","ðŸ“œ \u003Ca href=\"https://arxiv.org/abs/2309.16750\">Memory in Plain Sight\u003C/a> released on ArXiv!",{"date":139,"HTMLdescription":142},"ðŸŽ‰ \u003Ca href=\"https://arxiv.org/abs/2302.07253\">Energy Transformer\u003C/a> accepted to NeurIPS'23!",{"date":139,"HTMLdescription":144},"ðŸ§‘â€ðŸ« Gave a talk about \u003Ca href=\"https://arxiv.org/abs/2302.07253\">Energy Transformer\u003C/a> to the \u003Ca href=\"https://mcmahon.aep.cornell.edu/\">McMahon Lab\u003C/a>.",{"date":139,"HTMLdescription":146},"ðŸŽ‰ \u003Ca href=\"https://arxiv.org/abs/2203.16475\">ConceptEvo\u003C/a> accepted to CIKM'23!",{"date":148,"HTMLdescription":149},"Aug 2023","ðŸŽ‰ \u003Ca href=\"https://arxiv.org/abs/2305.03509\">Diffusion Explainer\u003C/a> accepted to VIS'23",{"date":148,"HTMLdescription":151},"ðŸš€ Released an \u003Ca href=\"https://amhn.vizhub.ai/demo/\">Associative Memory demo\u003C/a> that runs in your browser.  \u003C!-- Complete with all the mathy explanation bits. -->",{"date":148,"HTMLdescription":153},"ðŸ§‘â€ðŸ« Selected as a panelist for the \u003Ca href=\"https://amhn.vizhub.ai/\">AMHN Workshop\u003C/a> at NeurIPS'23.  \u003C!-- Come listen to hear my hot take on energy-based AI Frameworks. -->",{"date":155,"HTMLdescription":156},"Jun 2023","ðŸš€ Released \u003Ca href=\"https://molformer.res.ibm.com/\">Molformer\u003C/a>: a UI to explore AI-generated organic small molecules. See the \u003Ca target=\"_blank\" href=\"https://research.ibm.com/blog/ai-covid-antivirals?sf179606121=1\">blog at IBM Research\u003C/a> and paper at \u003Ca target=\"_blank\" href=\"https://www.science.org/doi/10.1126/sciadv.adg7865\">Science Advances\u003C/a>!",{"date":158,"HTMLdescription":159},"May 2023","ðŸ£ Became a dad ðŸ¤—ðŸ‘¶",{"date":161,"HTMLdescription":162},"Jan 2023","ðŸ“£ GATech highlighted my research in their \u003Ca href=\"https://www.cc.gatech.edu/news/manufacturing-finance-among-industries-benefit-whats-next-ai-2023\">College of Computing News\u003C/a>",{"Benjamin Hoover":164,"Hendrik Strobelt":168,"Mauro Martino":171,"Patrick Wang":174,"Stacy Tantum":177,"Jonathan Viventi":180,"Paul Bendich":183,"Carmen Rawls":186,"Eirik Adim Moreb":189,"Adam Yaseen":192,"Nisakorn Valyasevi":195,"Zoe Roecker":198,"Romel Menacho-Melgar":201,"Michael D. Lynch":204,"Sebastian Gehrmann":207,"Philippe Schwaller":210,"JL Reymond":213,"Teodoro Laino":216,"Peter Ajemba":219,"Keith Nogueira":222,"Enara Vijil":224,"Payel Das":226,"Samuel Hoffman":228,"Inkit Padhi":230,"Kar Wai Lim":232,"Matteo Manica":234,"Jannis Born":236,"Aleksandra Mojsilovic":238,"Arvind Satyanarayan":240,"Angie Boggust":242,"Yuchen Liang":244,"Chaitanya K. Ryali":246,"Leopold Grinberg":248,"Saket Navlakha":250,"Mohammed J. Zaki":252,"Dmitry Krotov":254,"Bao Pham":256,"Rameswar Panda":258,"Joseph Bullock":260,"Carolina Cuesta-Lazaro":262,"Arnau Quera-Bofarull":264,"Anjali Katta":266,"Katherine Hoffmann Pham":268,"Rebeca Moreno Jimenez":270,"Aidan Sedgewick":272,"Egmond Samir Evers":274,"David Kennedy":276,"Sandra Harlass":278,"Allen Gidraf Kahindo Maina":280,"Ahmad Hussien":282,"Miguel Luengo-Oroz":284,"Polo Chau":286,"Zijie J. Wang":287,"Evan Montoya":289,"Haoyang Yang":291,"David Munechika":293,"Haekyu Park":295,"Austin Wright":297,"Seongmin Lee":299,"ShengYun Peng":301,"Kevin Li":303,"Albert Webson":305,"Victor Sanh":307,"Johanna Beyer":309,"Hanspeter Pfister":311,"Alexander Rush":313,"Omar Shaikh":315,"Rahul Duggal":317,"Nilaksh Das":319,"Judy Hoffman":321,"Zsolt Kira":323,"Mahdi Roozbahani":325,"Eden Bensaid":327,"Zahra Ashktorab":329,"Casey Dugan":331,"James Johnson":333,"Aabhas Sharma":335,"Dustin Ramsey Torres":337,"Ingrid Lange":339,"Heiko Ludwig":341,"Bryant Chen":343,"Nathalie Baracaldo":345,"Werner Geyer":347,"Mikhail Yurochkin":349,"Hao Bang Yang":351,"Qian Pan":353,"Mayank Agarwal":355,"Aeree Cho":357,"Grace C. Kim":359,"Alexander Karpekov":361,"Alec Helbling":363},{"url":165,"picture":166,"me":167},"/","imgs/people/me-headshot.png",true,{"url":169,"picture":170},"http://hendrik.strobelt.com/","imgs/people/hendrik-strobelt.png",{"url":172,"picture":173},"http://www.mamartino.com","imgs/people/mauro-martino.png",{"url":175,"picture":176},"https://ece.duke.edu/faculty/patrick-wang","imgs/people/patrick-wang.png",{"url":178,"picture":179},"https://ece.duke.edu/faculty/stacy-tantum","imgs/people/stacy-tantum.png",{"url":181,"picture":182},"https://bme.duke.edu/faculty/jonathan-viventi","imgs/people/jonathan-viventi.png",{"url":184,"picture":185},"https://math.duke.edu/people/paul-l-bendich","imgs/people/paul-bendich.png",{"url":187,"picture":188},"https://boeingfellows.pratt.duke.edu/member/rawls","imgs/people/carmen-rawls.png",{"url":190,"picture":191},"https://lynchlab.pratt.duke.edu/people/e-adim-moreb","imgs/people/adim-moreb.png",{"url":193,"picture":194},"https://yin.hms.harvard.edu/cv/cv.yaseen.adam.pdf","imgs/people/adam-yaseen.png",{"url":196,"picture":197},"https://www.linkedin.com/in/nisavalyasevi/","imgs/people/nisa-valyasevi.png",{"url":199,"picture":200},"https://www.linkedin.com/in/zoe-roecker-5a417b104/","imgs/people/zoe-roecker.png",{"url":202,"picture":203},"https://www.linkedin.com/in/romel-menacho-melgar-0881b4a8/","imgs/people/romel-menacho-melgar.png",{"url":205,"picture":206},"https://lynchlab.pratt.duke.edu/people/michael-lynch","imgs/people/mike-lynch.png",{"url":208,"picture":209},"https://sebastiangehrmann.com/","imgs/people/sebastian-gehrmann.png",{"url":211,"picture":212},"https://pschwllr.github.io/#","imgs/people/philippe-schwaller.png",{"url":214,"picture":215},"http://www.gdb.unibe.ch/","imgs/people/jl-reymond.png",{"url":217,"picture":218},"https://researcher.watson.ibm.com/researcher/view.php?person=zurich-teo","imgs/people/teo-laino.png",{"url":220,"picture":221},"https://www.linkedin.com/in/peter-ajemba/","imgs/people/peter-ajemba.png",{"url":223},"https://www.linkedin.com/in/keith-public-profile/",{"url":225},"https://researcher.watson.ibm.com/researcher/view.php?person=us-ecvijil",{"url":227},"https://researcher.watson.ibm.com/researcher/view.php?person=us-daspa",{"url":229},"https://www.linkedin.com/in/shoffman5/",{"url":231},"https://scholar.google.co.in/citations?user=c4yuGSoAAAAJ&hl=en",{"url":233},"https://karwailim.github.io/",{"url":235},"https://researcher.watson.ibm.com/researcher/view.php?person=zurich-TTE",{"url":237},"https://researcher.watson.ibm.com/researcher/view.php?person=zurich-JAB",{"url":239},"https://scholar.google.com/citations?user=jnBZzGwAAAAJ&hl=en",{"url":241},"https://arvindsatya.com/",{"url":243},"http://angieboggust.com/",{"url":245},"https://airc.rpi.edu/people/staff/yuchen-liang",{"url":247},"https://scholar.google.com/citations?user=4LWx24UAAAAJ&hl=en",{"url":249},"http://www.dam.brown.edu/people/lgrinb/",{"url":251},"https://navlakhalab.net/",{"url":253},"http://www.cs.rpi.edu/~zaki/",{"url":255},"https://mitibmwatsonailab.mit.edu/people/dmitry-krotov/",{"url":257},"https://lemon-cmd.github.io/",{"url":259},"https://rpand002.github.io/",{"url":261},"https://josephpb.github.io/",{"url":263},"https://www.dur.ac.uk/research/directory/staff/?mode=staff&id=16714",{"url":265},"https://scholar.google.com/citations?user=8VGz9BIAAAAJ&hl=en",{"url":267},"https://www.humanityinaction.org/person/anjali-katta/",{"url":269},"https://katherinehoffmannpham.com/",{"url":271},"https://scholar.google.com/citations?user=v7qrOMQAAAAJ&hl=en",{"url":273},"https://www.dur.ac.uk/research/directory/staff/?mode=staff&id=16797",{"url":275},"https://www.linkedin.com/in/egmondevers/?originalSubdomain=bd",{"url":277},"https://www.lshtm.ac.uk/aboutus/people/kennedy.david",{"url":279},"https://www.linkedin.com/in/sandra-harlass-88b7b490/?originalSubdomain=de",{"url":281},"https://www.linkedin.com/in/allen-g-k-maina-5b4807b1/?originalSubdomain=ch",{"url":283},"https://www.linkedin.com/in/hussienahmad/?originalSubdomain=tn",{"url":285},"https://scholar.google.com/citations?user=MGU5C6MAAAAJ&hl=en",{"url":55},{"url":288},"https://zijie.wang/",{"url":290},"https://www.linkedin.com/in/evan-montoya-b252391b4/",{"url":292},"https://alexanderyang.me/",{"url":294},"https://www.linkedin.com/in/dmunechika/",{"url":296},"https://haekyu.com/",{"url":298},"https://www.austinpwright.com/",{"url":300},"http://www.seongmin.xyz/",{"url":302},"https://shengyun-peng.github.io/",{"url":304},"https://www.kevinyli.com/",{"url":306},"https://representation.ai/",{"url":308},"https://www.linkedin.com/in/victor-sanh/?locale=en_US",{"url":310},"https://johanna-b.github.io/",{"url":312},"https://vcg.seas.harvard.edu/people/hanspeter-pfister",{"url":314},"https://rush-nlp.com/",{"url":316},"http://oshaikh.com/",{"url":318},"http://www.rahulduggal.com/",{"url":320},"https://nilakshdas.com/",{"url":322},"https://faculty.cc.gatech.edu/~judy/",{"url":324},"https://faculty.cc.gatech.edu/~zk15/",{"url":326},"https://www.cse.gatech.edu/people/mahdi-roozbahani",{"url":328},"https://www.linkedin.com/in/eden-b-03397b136/",{"url":330},"http://zahraashktorab.com/",{"url":332},"https://www.linkedin.com/in/casey-dugan1/",{"url":334},"https://research.ibm.com/people/j-johnson",{"url":336},"https://www.linkedin.com/in/sharmaaabhas/",{"url":338},"https://dblp.org/pid/290/4172.html",{"url":340},"https://ingridlange.com/",{"url":342},"https://www.linkedin.com/in/heikoludwig/",{"url":344},"https://www.linkedin.com/in/bryant-chen-b372457/",{"url":346},"https://researcher.watson.ibm.com/researcher/view.php?person=us-baracald",{"url":348},"https://research.ibm.com/people/werner-geyer",{"url":350},"https://moonfolk.github.io/",{"url":352},"https://www.linkedin.com/in/hbyang",{"url":354},"https://www.linkedin.com/in/qian-pan-design/",{"url":356},"https://research.ibm.com/people/mayank-agarwal",{"url":358},"https://aereeeee.github.io/",{"url":360},"https://www.linkedin.com/in/chaeyeonggracekim/",{"url":362},"https://www.alexkarpekov.com/",{"url":364},"https://alechelbling.com/",[366,371,375,379,383,387,390],{"name":367,"year":368,"month":369,"url":370},"Engadget",2020,"April","https://www.engadget.com/ibm-coronavirus-ai-research-tools-162123059.html",{"name":372,"year":373,"month":369,"url":374},"ACS",2021,"https://cen.acs.org/acs-news/acs-meeting-news/Machine-learning-maps-atoms/99/web/2021/04",{"name":376,"year":373,"month":377,"url":378},"Discover Magazine","January","https://www.discovermagazine.com/the-sciences/fruit-fly-brain-network-hacked-for-language-processing",{"name":380,"year":373,"month":381,"url":382},"Yannic Kilcher's Vlog","August","https://www.youtube.com/watch?v=gFkBqD2hbnU&t=1485s",{"name":384,"year":385,"month":369,"url":386},"SciTechDaily",2022,"https://scitechdaily.com/do-humans-and-ai-think-alike/",{"name":388,"year":385,"month":369,"url":389},"FreeThink","https://www.freethink.com/hard-tech/trustworthy-ai",{"name":391,"year":43,"month":369,"url":392},"GA Tech College of Computing: What's Next in AI","https://www.cc.gatech.edu/news/manufacturing-finance-among-industries-benefit-whats-next-ai-2023",[394,438,460,490,510,533,564,586,607,625,649,662,679,702,724,744,772,796,820,840],{"id":395,"title":396,"shortTitle":397,"category":398,"authors":399,"venue":407,"venueShorthand":408,"thumbnail":409,"type":410,"defaultUrl":411,"links":412,"awards":428,"month":435,"year":436,"featured":167,"featureDescription":437,"selected":167},"TransformerExplainer","Transformer Explainer: Interactive Learning of Text-Generative Models","Transformer Explainer","vis",[400,401,402,403,404,405,406,103],"Aeree Cho","Grace C. Kim","Alexander Karpekov","Alec Helbling","Zijie J. Wang","Seongmin Lee","Benjamin Hoover","IEEE Transactions on Visualization and Computer Graphics","VIS","imgs/thumbnails/PlainSight.png","conference","https://poloclub.github.io/transformer-explainer/",[413,416,420,424],{"type":414,"url":411,"label":415},"demo","Demo",{"type":417,"url":418,"label":419},"pdf","https://arxiv.org/abs/2408.04619","PDF",{"type":421,"url":422,"label":423,"showStars":167},"code","https://github.com/poloclub/transformer-explainer","Code",{"type":425,"url":426,"label":427},"video","https://www.youtube.com/watch?v=ECR4oAwocjs","Video",[429,432],{"name":430,"url":431},"Went Viral on X (â¤ 1.9kï¸+)","https://twitter.com/omarsar0/status/1821986172215742716",{"name":433,"url":434},"#1 paper of the dayðŸ¤—","https://huggingface.co/papers/2408.04619","Oct",2024,"Transformers are the most powerful AI innovation of the last decade. Learn how they work by interacting with every mechanic from the comfort of your web browser.",{"id":439,"title":440,"shortTitle":441,"category":442,"authors":443,"venue":446,"venueShorthand":40,"thumbnail":409,"type":447,"defaultUrl":448,"links":449,"month":435,"year":43,"featured":167,"featureDescription":458,"selected":167,"bibtex":459},"PlainSight","Memory in Plain Sight: A Survey of the Uncanny Resemblances between Diffusion Models and Associative Memories","Memory in Plain Sight","memory",[406,80,81,444,445,103],"Judy Hoffman","Zsolt Kira","NeurIPS Workshop on Associative Memory and Hopfield Networks","workshop","https://arxiv.org/abs/2309.16750",[450,451,454],{"type":417,"url":448,"label":419},{"type":417,"url":452,"label":453},"/posters/memory-in-plain-sight-24x36.pdf","Poster",{"type":455,"url":456,"label":457},"url","/memory-in-plain-sight","Home","We are the first work to discover that diffusion models perform memory retrieval in their denoising dynamics.","\n@misc{hoover2023memory,\n  title={Memory in Plain Sight: A Survey of the Uncanny Resemblances between Diffusion Models and Associative Memories}, \n  author={Benjamin Hoover and Hendrik Strobelt and Dmitry Krotov and Judy Hoffman and Zsolt Kira and Duen Horng Chau},\n  year={2023},\n  eprint={2309.16750},\n  archivePrefix={arXiv},\n  primaryClass={cs.LG}\n}",{"id":461,"title":462,"shortTitle":462,"category":442,"authors":463,"venue":468,"venueShorthand":469,"location":470,"defaultUrl":471,"links":472,"month":486,"year":43,"featured":167,"selected":167,"thumbnail":487,"type":410,"featureDescription":488,"bibtex":489},"EnergyTransformer","Energy Transformer",[406,464,465,466,80,103,467,81],"Yuchen Liang","Bao Pham","Rameswar Panda","Mohammed J. Zaki","Conference on Neural Information Processing Systems","NeurIPS","New Orleans, LA, USA","/energy-transformer",[473,475,477,478,480,483],{"type":417,"url":474,"label":419},"https://arxiv.org/abs/2302.07253",{"type":417,"url":476,"label":453},"/posters/energy-transformer-24x36.pdf",{"type":455,"url":471,"label":457},{"type":421,"url":479,"label":423,"showStars":167},"https://github.com/bhoov/energy-transformer-jax",{"type":425,"url":481,"label":482},"https://recorder-v3.slideslive.com/#/share?share=88188&s=6a61b5bf-c59b-4ef5-b71f-be4156c92dd5","Video (5m)",{"type":425,"url":484,"label":485},"https://online.kitp.ucsb.edu/online/deeplearning23/krotov/rm/jwvideo.html","Video (45m)","Dec.","imgs/thumbnails/energy-transformer.png","We derive an Associative Memory inspired by the famous Transformer architecture, where the forward pass through the model is memory retrieval by energy descent.","\n@inproceedings{\n  hoover2023energybased,\n  title={Energy Transformer},\n  author={Hoover, Benjamin and Liang, Yuchen and Pham, Bao and Panda, Rameswar and Strobelt, Hendrik and Chau, Duen Horng and Zaki, Mohammed J. and Krotov, Dmitry},\n  booktitle={Thirty-seventh Conference on Neural Information Processing Systems},\n  year={2023},\n  url={https://arxiv.org/abs/2302.07253}\n}",{"id":491,"title":492,"shortTitle":491,"category":398,"authors":493,"venue":500,"venueShorthand":501,"type":410,"location":502,"month":503,"year":43,"defaultUrl":504,"links":505,"description":508,"bibtex":509},"ConceptEvo","ConceptEvo: Interpreting Concept Evolution in Deep Learning Training",[494,405,406,495,496,497,498,499,444,103],"Haekyu Park","Austin Wright","Omar Shaikh","Rahul Duggal","Nilaksh Das","Kevin Li","ACM International Conference on Information and Knowledge Management","CIKM","Birmingham, UK","July","https://openreview.net/forum?id=NayaT7pLUx",[506],{"type":417,"url":507,"label":419},"https://arxiv.org/abs/2203.16475","Accepted to CIKM 2023. Also presented at AI & HCI Workshop at ICML 2023","\n@inproceedings{park2022conceptevo,\n  title={ConceptEvo: Interpreting Concept Evolution in Deep Learning Training},\n  author={Park, Haekyu and Lee, Seongmin and Hoover, Benjamin and Wright, Austin and Shaikh, Omar and Duggal, Rahul and Das, Nilaksh and Hoffman, Judy and Chau, Duen Horng},\n  journal={Thirty-second Conference on Information and Knowledge Management},\n  year={2023}\n}\n",{"id":511,"title":512,"shortTitle":513,"category":398,"authors":514,"venue":407,"venueShorthand":408,"location":517,"type":410,"featured":167,"selected":518,"featureDescription":519,"thumbnail":520,"defaultUrl":521,"links":522,"month":530,"year":436,"description":531,"bibtex":532},"DiffusionExplainer","Diffusion Explainer: Visual Explanation for Text-to-image Stable Diffusion","Diffusion Explainer",[405,406,80,404,515,495,499,494,516,103],"ShengYun Peng","Haoyang Yang","Florida, USA",false,"Diffusion models are complicated. We break down Stable Diffusion and explain each component of the model visually.","imgs/thumbnails/diffusion-explainer.png","https://poloclub.github.io/diffusion-explainer/",[523,524,526,528],{"type":414,"url":521,"label":415},{"type":417,"url":525,"label":419},"https://arxiv.org/abs/2305.03509",{"type":425,"url":527,"label":427},"https://www.youtube.com/watch?v=Zg4gxdIWDds",{"type":421,"url":529,"label":423,"showStars":167},"https://github.com/poloclub/diffusion-explainer","Oct.","Short Paper at VIS'24. Taught at graduate computer vision course","\n@article{lee2023diffusion,\n  title={Diffusion Explainer: Visual Explanation for Text-to-image Stable Diffusion},\n  author={Lee, Seongmin and Hoover, Benjamin and Strobelt, Hendrik and Wang, Zijie J and Peng, ShengYun and Wright, Austin and Li, Kevin and Park, Haekyu and Yang, Haoyang and Chau, Duen Horng},\n  journal={arXiv preprint arXiv:2305.03509},\n  year={2023}\n}",{"id":534,"title":535,"shortTitle":534,"category":536,"authors":537,"venue":540,"venueShorthand":541,"type":410,"location":542,"defaultUrl":543,"links":544,"awards":553,"month":503,"year":43,"description":562,"bibtex":563},"DiffusionDB","DiffusionDB: A Large-scale Prompt Gallery Dataset for Text-to-Image Generative Models","dataset",[404,538,539,516,406,103],"Evan Montoya","David Munechika","Association for Computational Linguistics","ACL","Toronto, CA","https://poloclub.github.io/diffusiondb/",[545,546,548,551],{"type":455,"url":543,"label":457},{"type":421,"url":547,"label":423,"showStars":167},"https://github.com/poloclub/diffusiondb",{"type":421,"url":549,"label":550},"https://huggingface.co/datasets/poloclub/diffusiondb","Dataset",{"type":417,"url":552,"label":419},"https://arxiv.org/abs/2210.14896",[554,556,559],{"name":7,"url":555},"https://2023.aclweb.org/program/best_papers/",{"name":557,"url":558},"Went Viral","https://twitter.com/jay4w/status/1592922807998218241",{"name":560,"url":561},"Oral Presentation","https://aclanthology.org/2023.acl-long.51/","ðŸ† Honorable Mention (Top 1.6% of submissions) and Oral presentation at ACL 2023 # https://2023.aclweb.org/program/best_papers/","\n@inproceedings{wangDiffusionDBLargescalePrompt2023,\n  title = {{{DiffusionDB}}: {{A}} Large-Scale Prompt Gallery Dataset for Text-to-Image Generative Models},\n  booktitle = {Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: {{Long}} Papers)},\n  author = {Wang, Zijie J. and Montoya, Evan and Munechika, David and Yang, Haoyang and Hoover, Benjamin and Chau, Duen Horng},\n  year = {2023},\n  url = {https://aclanthology.org/2023.acl-long.51}\n}",{"id":565,"title":566,"shortTitle":567,"category":398,"authors":568,"venue":575,"venueShorthand":576,"type":410,"location":577,"defaultUrl":578,"links":579,"thumbnail":581,"month":582,"year":43,"featured":518,"selected":518,"featureDescription":583,"description":584,"bibtex":585},"FairBERT","Fairness Evaluation in Text Classification: Machine Learning Practitioner Perspectives of Individual and Group Fairness","Fairness Evaluation in Text Classification",[569,406,570,571,572,573,574],"Zahra Ashktorab","Mayank Agarwal","Casey Dugan","Werner Geyer","Hao Bang Yang","Mikhail Yurochkin","Conference on Human Factors in Computing Systems","CHI","Hamburg, Germany","https://dl.acm.org/doi/full/10.1145/3544548.3581227",[580],{"type":417,"url":578,"label":419},"imgs/thumbnails/fairbert.jpeg","Apr","We evaluate how different machine learning practitioners perceive \"fairness\" in language models.","Poster at CHI 2023","\n@inproceedings{ashktorab2023fairness,\n  title={Fairness Evaluation in Text Classification: Machine Learning Practitioner Perspectives of Individual and Group Fairness},\n  author={Ashktorab, Zahra and Hoover, Benjamin and Agarwal, Mayank and Dugan, Casey and Geyer, Werner and Yang, Hao Bang and Yurochkin, Mikhail},\n  booktitle={Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},\n  pages={1--20},\n  year={2023}\n}",{"id":587,"title":588,"shortTitle":587,"category":442,"authors":589,"venue":590,"venueShorthand":591,"type":447,"location":470,"defaultUrl":592,"links":593,"thumbnail":602,"month":603,"year":385,"featured":167,"selected":167,"featureDescription":604,"description":605,"bibtex":606},"HAMUX","HAMUX: A Universal Abstraction for Hierarchical Hopfield Networks",[406,103,80,81],"Symbiosis of Deep Learning and Differential Equations II Workshop at NeurIPS","DLDE","https://bhoov.github.io/hamux/",[594,596,598,600],{"type":421,"url":595,"label":423,"showStars":167},"https://github.com/bhoov/hamux",{"type":455,"url":592,"label":597},"Project",{"type":417,"url":599,"label":419},"https://openreview.net/pdf?id=SAv3nhzNWhw",{"type":425,"url":601,"label":427},"https://youtu.be/x_jJed5KjP8","imgs/thumbnails/hamux-thumbnail.jpg","Dec","We invent a software abstraction around \"synapses\" and \"neurons\" to assemble energy functions of complicated Associative Memories, where memory retrieval is performed through autograd.","\u003Cstrong>ðŸ†Spotlight Poster\u003C/strong> at \u003Ca href=\"https://dlde-2022.github.io/\" target=\"_blank\">DLDE Workshop\u003C/a>,  Poster at \u003Ca href=\"https://memari-workshop.github.io/\" target=\"_blank\">MemARI Workshop\u003C/a>, NeurIPS 2022","\n@article{hooverUniversal,\n  title={A Universal Abstraction for Hierarchical Hopfield Networks},\n  author={Hoover, Benjamin and Chau, Duen Horng and Strobelt, Hendrik and Krotov, Dmitry},\n  booktitle={The Symbiosis of Deep Learning and Differential Equations II}\n}",{"id":608,"title":609,"name":608,"category":398,"authors":610,"venue":407,"venueShorthand":408,"type":410,"location":616,"year":385,"month":530,"defaultUrl":617,"links":618,"featured":518,"description":623,"bibtex":624},"PromptIDE","Interactive and Visual Prompt Engineering for Ad-hoc Task Adaptation with Large Language Models",[80,611,612,406,613,614,615],"Albert Webson","Victor Sanh","Johanna Beyer","Hanspeter Pfister","Alexander Rush","Oklahoma City, OK, USA","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9908590",[619,621],{"type":417,"url":620,"label":419},"https://arxiv.org/abs/2208.07852",{"type":414,"url":622,"label":415},"http://promptide.vizhub.ai/","Published at IEEE Vis 2022","\n@article{9908590,\n  author={Strobelt, Hendrik and Webson, Albert and Sanh, Victor and Hoover, Benjamin and Beyer, Johanna and Pfister, Hanspeter and Rush, Alexander M.},\n  journal={IEEE Transactions on Visualization and Computer Graphics}, \n  title={Interactive and Visual Prompt Engineering for Ad-hoc Task Adaptation with Large Language Models}, \n  year={2023},\n  volume={29},\n  number={1},\n  pages={1146-1156},\n  doi={10.1109/TVCG.2022.3209479}\n  }",{"id":626,"title":627,"shortTitle":628,"category":398,"authors":629,"year":385,"month":632,"venue":633,"venueShorthand":576,"type":410,"location":470,"defaultUrl":634,"links":635,"thumbnail":645,"featured":518,"featureDescription":646,"description":647,"bibtex":648},"SharedInterest","Shared Interest: Measuring Human-AI Alignment to Identify Recurring Patterns in Model Behavior","Shared Interest",[630,406,631,80],"Angie Boggust","Arvind Satyanarayan","Apr.","ACM Conference on Human Factors in Computing Systems","http://shared-interest.csail.mit.edu/",[636,637,639,641,643],{"type":455,"url":634,"label":597},{"type":414,"url":638,"label":415},"http://shared-interest.csail.mit.edu/computer-vision/client/index.html",{"type":425,"url":640,"label":427},"https://www.youtube.com/watch?v=1SSgr96nBDc",{"type":417,"url":642,"label":419},"https://dl.acm.org/doi/pdf/10.1145/3491102.3501965",{"type":421,"url":644,"label":423},"https://github.com/mitvis/shared-interest","imgs/thumbnails/saliencyExplorer.png","Do humans and AI models agree on what features are important for model prediction? How much do they differ?","\u003Cstrong>ðŸ…Best Paper Honorable Mention\u003C/strong> CHI 2022; IEE Vis: VisXAI Workshop; Demo at NeurIPS 2020","\n@inproceedings{2022-shared-interest,\n  title = {{Shared Interest: Measuring Human-AI Alignment to Identify Recurring Patterns in Model Behavior}},\n  author = {Angie Boggust AND Benjamin Hoover AND Arvind Satyanarayan AND Hendrik Strobelt},\n  booktitle = {ACM Human Factors in Computing Systems (CHI)},\n  year = {2022},\n  doi = {10.1145/3491102.3501965},\n  url = {http://vis.csail.mit.edu/pubs/shared-interest}\n}",{"id":650,"title":651,"shortTitle":652,"category":398,"authors":653,"venue":654,"venueShorthand":469,"year":373,"month":603,"type":414,"defaultUrl":655,"links":656,"description":660,"bibtex":661},"60years","Interactive Exploration for 60 Years of AI Research","VisAnthology",[80,406],"Conference on Neural Information Processing Systems: Demo","https://neuripsav.vizhub.ai/",[657,658],{"type":414,"url":655,"label":415},{"type":417,"url":659,"label":419},"https://neuripsav.vizhub.ai/NeurIPS_demo_2021_60years.pdf","Demo at NeurIPS 2021","\n@inproceedings{strobelt2021interactive,\n  title={Interactive Exploration for 60 Years of AI Research},\n  author={Strobelt, Hendrik and Hoover, Benjamin},\n  booktitle={Annual Conference on Neural Information Processing Systems},\n  year={2021}\n  URL = { https://neuripsav.vizhub.ai/NeurIPS_demo_2021_60years.pdf},\n}",{"id":663,"title":664,"shortTitle":663,"category":398,"authors":665,"venue":668,"venueShorthand":669,"year":373,"month":670,"type":671,"defaultUrl":672,"links":673,"featured":518,"description":677,"bibtex":678},"Fairytailor","Fairytailor: A multimodal generative framework for storytelling",[666,667,406,80],"Eden Bensaid","Mauro Martino","ArXiv preprint","ArXiv","Jul","preprint","https://arxiv.org/pdf/2108.04324.pdf",[674,675],{"type":417,"url":672,"label":419},{"type":414,"url":676,"label":415},"https://fairytailor.vizhub.ai/","An AI co-authoring tool to interactively write text and images into a story resembling a child's fairytale.","\n@article{bensaid2021fairytailor,\n  title={Fairytailor: A multimodal generative framework for storytelling},\n  author={Bensaid, Eden and Martino, Mauro and Hoover, Benjamin and Strobelt, Hendrik},\n  journal={arXiv preprint arXiv:2108.04324},\n  year={2021}\n  url={https://arxiv.org/abs/2108.04324}\n}",{"id":680,"title":681,"shortTitle":680,"category":442,"authors":682,"venue":686,"venueShorthand":687,"year":373,"month":688,"defaultUrl":689,"links":690,"thumbnail":699,"type":410,"description":700,"bibtex":701},"FlyVec","Can a Fruit Fly Learn Word Embeddings?",[464,683,406,684,685,467,81],"Chaitanya K. Ryali","Leopold Grinberg","Saket Navlakha","International Conference for Learning Representations","ICLR","May","https://flyvec.vizhub.ai",[691,692,694,697],{"type":455,"url":689,"label":597},{"type":417,"url":693,"label":419},"https://arxiv.org/abs/2101.06887",{"type":695,"url":696,"label":453},"poster","https://iclr.cc/virtual/2021/poster/3085",{"type":421,"url":698,"label":423,"showStars":167},"https://github.com/bhoov/flyvec","imgs/thumbnails/flyvec.png","Poster at ICLR 2021","@misc{liang2021fruit,\n    title={Can a Fruit Fly Learn Word Embeddings?}, \n    author={Yuchen Liang and Chaitanya K. Ryali and Benjamin Hoover and Leopold Grinberg and Saket Navlakha and Mohammed J. Zaki and Dmitry Krotov},\n    year={2021},\n    eprint={2101.06887},\n    url = \"https://arxiv.org/pdf/2101.06887.pdf\",\n    archivePrefix={arXiv},\n    primaryClass={cs.CL}\n}",{"id":703,"title":704,"shortTitle":703,"category":398,"authors":705,"venue":707,"venueShorthand":708,"location":709,"month":582,"year":373,"defualtUrl":710,"links":711,"thumbnail":720,"type":414,"featured":518,"featureDescription":721,"description":722,"bibtex":723},"LMdiff","LMdiff: A Visual Diff Tool to Compare Language Models",[80,406,631,706],"Sebastian Gehrmann","Empirical Methods in Natural Language Processing: Systems Demo","EMNLP","Punta Cana, Dominican Republic","http://lmdiff.net/",[712,713,714,716,718],{"type":455,"url":710,"label":597},{"type":414,"url":710,"label":415},{"type":425,"url":715,"label":427},"https://vimeo.com/640945461",{"type":417,"url":717,"label":419},"https://arxiv.org/abs/2111.01582",{"type":421,"url":719,"label":423},"https://github.com/HendrikStrobelt/LMdiff","imgs/thumbnails/diffLM.png","We visually compare large, complex language models. How do different models interpret the same text?","System Demo at EMNLP 2021. \u003Cb>Best Demo\u003C/b> at Neurips 2020","@inproceedings{strobelt-etal-2021-lmdiff,\n  title = \"{LM}diff: A Visual Diff Tool to Compare Language Models\",\n  author = \"Strobelt, Hendrik  and\n    Hoover, Benjamin  and\n    Satyanaryan, Arvind  and\n    Gehrmann, Sebastian\",\n  booktitle = \"Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing: System Demonstrations\",\n  month = nov,\n  year = \"2021\",\n  address = \"Online and Punta Cana, Dominican Republic\",\n  publisher = \"Association for Computational Linguistics\",\n  url = \"https://aclanthology.org/2021.emnlp-demo.12\",\n  doi = \"10.18653/v1/2021.emnlp-demo.12\",\n  pages = \"96--105\",\n  abstract = \"While different language models are ubiquitous in NLP, it is hard to contrast their outputs and identify which contexts one can handle better than the other. To address this question, we introduce LMdiff, a tool that visually compares probability distributions of two models that differ, e.g., through finetuning, distillation, or simply training with different parameter sizes. LMdiff allows the generation of hypotheses about model behavior by investigating text instances token by token and further assists in choosing these interesting text instances by identifying the most interesting phrases from large corpora. We showcase the applicability of LMdiff for hypothesis generation across multiple case studies. A demo is available at http://lmdiff.net .\",\n}",{"id":725,"title":726,"shortTitle":727,"category":398,"authors":728,"venue":737,"venueShorthand":738,"location":739,"type":410,"year":373,"month":582,"defaultUrl":740,"links":741,"bibtex":743},"Poisoning","The Design and Development of a Game to Study Backdoor Poisoning Attacks: The Backdoor Game","The Backdoor Game",[569,571,729,730,731,732,406,733,734,735,572,736],"James Johnson","Aabhas Sharma","Dustin Ramsey Torres","Ingrid Lange","Heiko Ludwig","Bryant Chen","Nathalie Baracaldo","Qian Pan","International Conference on Intelligent User Interfaces","IUI","(online)","http://zahraashktorab.com/iui21-13.pdf",[742],{"type":417,"url":740,"label":419},"\n@inproceedings{10.1145/3397481.3450647,\n  author = {Ashktorab, Zahra and Dugan, Casey and Johnson, James and Sharma, Aabhas and Torres, Dustin Ramsey and Lange, Ingrid and Hoover, Benjamin and Ludwig, Heiko and Chen, Bryant and Baracaldo, Nathalie and Geyer, Werner and Pan, Qian},\n  title = {The Design and Development of a Game to Study Backdoor Poisoning Attacks: The Backdoor Game},\n  year = {2021},\n  isbn = {9781450380171},\n  publisher = {Association for Computing Machinery},\n  address = {New York, NY, USA},\n  url = {https://doi.org/10.1145/3397481.3450647},\n  doi = {10.1145/3397481.3450647},\n  booktitle = {26th International Conference on Intelligent User Interfaces},\n  pages = {423â€“433},\n  numpages = {11},\n  keywords = {activation clustering, backdoor poisoning, gamification, AI security},\n  location = {College Station, TX, USA},\n  series = {IUI '21}\n}",{"id":745,"title":746,"name":747,"category":398,"authors":748,"venue":762,"venueShorthand":763,"type":764,"year":373,"month":765,"defaultUrl":766,"links":767,"thumbnail":769,"description":770,"bibtex":771},"CampEPI","Operational response simulation tool for epidemics within refugee and IDP settlements","Refugee Camp Epidemic Simulation",[749,750,751,752,753,406,80,754,755,756,757,758,759,760,761],"Joseph Bullock","Carolina Cuesta-Lazaro","Arnau Quera-Bofarull","Anjali Katta","Katherine Hoffmann Pham","Rebeca Moreno Jimenez","Aidan Sedgewick","Egmond Samir Evers","David Kennedy","Sandra Harlass","Allen Gidraf Kahindo Maina","Ahmad Hussien","Miguel Luengo-Oroz","Public Library of Science: Computational Biology","PLOS","journal","Jan","https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1009360",[768],{"type":417,"url":766,"label":419},"imgs/thumbnails/junevis.png","An operational response simulation tool for epidemics within settlements","@article{aylett2021operational,\n  title={Operational response simulation tool for epidemics within refugee and IDP settlements: A scenario-based case study of the Coxâ€™s Bazar settlement},\n  author={Aylett-Bullock, Joseph and Cuesta-Lazaro, Carolina and Quera-Bofarull, Arnau and Katta, Anjali and Hoffmann Pham, Katherine and Hoover, Benjamin and Strobelt, Hendrik and Moreno Jimenez, Rebeca and Sedgewick, Aidan and Samir Evers, Egmond and others},\n  journal={PLoS computational biology},\n  volume={17},\n  number={10},\n  pages={e1009360},\n  year={2021},\n  publisher={Public Library of Science San Francisco, CA USA}\n}",{"id":773,"title":774,"shortTitle":773,"category":398,"authors":775,"venue":779,"venueShorthand":780,"year":368,"month":603,"type":764,"featured":167,"selected":518,"featureDescription":781,"defaultUrl":782,"links":783,"thumbnail":793,"description":794,"bibtex":795},"RXNMapper","RXNMapper: Unsupervised Attention Guided Atom Mapping",[776,406,777,80,778],"Philippe Schwaller","JL Reymond","Teodoro Laino","Science Advances","AAAS","We discover that Transformers trained on chemical reactions learn, on their own, how atoms physically rearrange.","http://rxnmapper.ai/",[784,785,787,789,791],{"type":455,"url":782,"label":597},{"type":414,"url":786,"label":415},"http://rxnmapper.ai/demo.html",{"type":417,"url":788,"label":419},"https://advances.sciencemag.org/content/7/15/eabe4166",{"type":425,"url":790,"label":427},"https://vimeo.com/434757113",{"type":421,"url":792,"label":423,"showStars":167},"https://github.com/rxn4chemistry/rxnmapper","imgs/thumbnails/rxnmapper.png","Published in Science Advances 2021; \u003Cstrong>Best Poster\u003C/strong> at  \u003Ca target=\"_blank\" href=\"https://ioppublishing.org/news/announcing-the-winners-of-ioppposter/?utm_source=PR&utm_medium=cpc&utm_campaign=IOPPposter&utm_term=IOPPposterConference\">#IOPPoster\u003C/a>, Poster at ICML 2020 Workshop: AI for Scientific Discovery &amp; ACS Fall 2020","@article{schwaller2021extraction,\n  title={Extraction of organic chemistry grammar from unsupervised learning of chemical reactions},\n  author={Schwaller, Philippe and Hoover, Benjamin and Reymond, Jean-Louis and Strobelt, Hendrik and Laino, Teodoro},\n  journal={Science Advances},\n  volume={7},\n  number={15},\n  pages={eabe4166},\n  year={2021},\n  publisher={American Association for the Advancement of Science}\n}",{"id":797,"title":798,"name":799,"category":398,"authors":800,"venue":809,"venueShorthand":469,"type":410,"year":368,"month":603,"defaultUrl":810,"links":811,"thumbnail":817,"description":818,"bibtex":819},"CogMol","CogMol: Target-Specific and Selective Drug Design for COVID-19 Using Deep Generative Models","CogMol: COVID-19 Drug Design",[801,802,803,80,804,805,406,806,807,778,808],"Enara Vijil","Payel Das","Samuel Hoffman","Inkit Padhi","Kar Wai Lim","Matteo Manica","Jannis Born","Aleksandra Mojsilovic","Neural Information Processing Systems","https://papers.nips.cc/paper/2020/file/2d16ad1968844a4300e9a490588ff9f8-Paper.pdf",[812,814,816],{"type":455,"url":813,"label":597},"https://covid19-mol.mybluemix.net/",{"type":414,"url":815,"label":415},"https://covid19-mol.mybluemix.net/new",{"type":417,"url":810,"label":419},"imgs/thumbnails/cogmol.png","\u003Cstrong>ðŸ†Spotlight Poster\u003C/strong> at Neurips 2020","\nNeurips citation available soon.\n@misc{chenthamarakshan2020cogmol,\n    title={CogMol: Target-Specific and Selective Drug Design for COVID-19 Using Deep Generative Models}, \n    author={Vijil Chenthamarakshan and Payel Das and Samuel C. Hoffman and Hendrik Strobelt and Inkit Padhi and Kar Wai Lim and Benjamin Hoover and Matteo Manica and Jannis Born and Teodoro Laino and Aleksandra Mojsilovic},\n    year={2020},\n    eprint={2004.01215},\n    archivePrefix={arXiv},\n    primaryClass={cs.LG}\n}",{"id":821,"title":822,"shortTitle":821,"category":398,"authors":823,"venue":824,"venueShorthand":541,"location":739,"year":368,"month":670,"defaultUrl":825,"links":826,"featured":518,"featureDescription":836,"thumbnail":837,"type":410,"description":838,"bibtex":839},"exBERT","exBERT: A Visual Analysis of Transformer Models",[406,80,706],"Association for Computational Linguistics: System Demonstrations","https://exbert.vizhub.ai",[827,828,830,832,834],{"type":455,"url":825,"label":597},{"type":414,"url":829,"label":415},"https://exbert.vizhub.ai/exBERT.html",{"type":417,"url":831,"label":419},"https://www.aclweb.org/anthology/2020.acl-demos.22/",{"type":425,"url":833,"label":427},"https://www.youtube.com/watch?v=e31oyfo_thY&feature=youtu.be",{"type":421,"url":835,"label":423,"showStars":167},"https://github.com/bhoov/exbert","Transformers are giant black boxes. We break open BERT and GPT-like models and visualize attentions, discovering meaningful semantic information stored in the learned embeddings.","imgs/thumbnails/exBERT.png","System Demo at ACL 2020. Nominated for \u003Cstrong>Best Demo\u003C/strong> at Neurips 2019.","\n@inproceedings{hoover-etal-2020-exbert,\n  title = \"{exBERT: A Visual Analysis Tool to Explore Learned Representations in Transformer Models}\",\n  author = \"Hoover, Benjamin  and\n    Strobelt, Hendrik  and\n    Gehrmann, Sebastian\",\n  booktitle = \"Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics: System Demonstrations\",\n  month = jul,\n  year = \"2020\",\n  address = \"Online\",\n  publisher = \"Association for Computational Linguistics\",\n  url = \"https://www.aclweb.org/anthology/2020.acl-demos.22\",\n  doi = \"10.18653/v1/2020.acl-demos.22\",\n  pages = \"187--196\",\n}",{"id":841,"title":842,"shortTitle":843,"authors":844,"venue":849,"venueShorthand":372,"year":850,"month":851,"type":764,"defaultUrl":852,"links":853,"thumbnail":855,"bibtex":856},"SOS","Managing the SOS Response for Enhanced  CRISPR-Cas-Based Recombineering in E. coli  through Transient Inhibition of Host RecA Activity","Cas9 RecA Inhibition",[113,406,845,846,847,848,114],"Adam Yaseen","Nisakorn Valyasevi","Zoe Roecker","Romel Menacho-Melgar","American Chemical Society: Synthetic Biology",2017,"Sep","https://pubs.acs.org/doi/pdf/10.1021/acssynbio.7b00174",[854],{"type":417,"url":852,"label":419},"imgs/thumbnails/sos.png","\n@article{doi:10.1021/acssynbio.7b00174,\n  author = {Moreb, Eirik Adim and Hoover, Benjamin and Yaseen, Adam and Valyasevi, Nisakorn and Roecker, Zoe and Menacho-Melgar, Romel and Lynch, Michael D.},\n  title = {Managing the SOS Response for Enhanced CRISPR-Cas-Based Recombineering in E.Â coli through Transient Inhibition of Host RecA Activity},\n  journal = {ACS Synthetic Biology},\n  volume = {6},\n  number = {12},\n  pages = {2209-2218},\n  year = {2017},\n  doi = {10.1021/acssynbio.7b00174}, \n  note = {PMID: 28915012},\n  URL = { https://doi.org/10.1021/acssynbio.7b00174 },\n  eprint = { https://doi.org/10.1021/acssynbio.7b00174 }\n}",[858,862,870,878,884,890,898],{"venue":859,"venueShorthand":40,"years":860},"Workshop on Associative Memory & Hopfield Networks at NeurIPS",[861],{"year":43,"url":44},{"venue":686,"venueShorthand":687,"years":863},[864,866,868],{"year":436,"url":865},"https://iclr.cc/Conferences/2024",{"year":43,"url":867},"https://iclr.cc/Conferences/2023",{"year":385,"url":869},"https://iclr.cc/Conferences/2022",{"venue":871,"venueShorthand":872,"years":873},"International Conference for Machine Learning","ICML",[874,876],{"year":43,"url":875},"https://icml.cc/Conferences/2023",{"year":385,"url":877},"https://icml.cc/Conferences/2022",{"venue":879,"venueShorthand":880,"years":881},"Blogpost Track at ICLR","BP@ICLR",[882],{"year":43,"url":883},"https://iclr-blogposts.github.io/2023/about",{"venue":885,"venueShorthand":886,"years":887},"Workshop on the Symbiosis of Deep Learning and Differential Equations at NeurIPS","DLDE@NeurIPS",[888],{"year":385,"url":889},"https://dlde-2022.github.io/",{"venue":809,"venueShorthand":469,"years":891},[892,894,896],{"year":436,"url":893},"https://nips.cc/Conferences/2024",{"year":43,"url":895},"https://nips.cc/Conferences/2023",{"year":373,"url":897},"https://nips.cc/Conferences/2021",{"venue":633,"venueShorthand":576,"years":899},[900],{"year":43,"url":901},"https://chi2023.acm.org/",{"scholar":903,"linkedin":908,"twitter":914,"github":921,"homepage":929,"email":934,"cvpdf":939},{"name":904,"href":905,"dataIcon":906,"icon":907,"label":904},"Google Scholar","https://scholar.google.com/citations?user=n10P0tYAAAAJ&hl=en","mdi-school","icons/scholar.svg",{"name":909,"href":910,"dataIcon":911,"icon":912,"label":913},"LinkedIn","https://www.linkedin.com/in/benhoov/","mdi-linkedin","icons/linkedin.svg","benhoov",{"name":915,"href":916,"faIcon":917,"dataIcon":918,"icon":919,"label":920},"Twitter","https://twitter.com/ben_hoov","fa-twitter","mdi-twitter","icons/twitter.svg","@ben_hoov",{"name":922,"group":923,"href":924,"faIcon":925,"label":926,"icon":927,"dataIcon":928},"Github",1,"https://github.com/bhoov","fa-github","@bhoov","icons/github-alt.svg","mdi-github",{"name":930,"href":165,"faIcon":931,"icon":932,"label":933},"Homepage","fa-house","icons/home.svg","bhoov.com",{"name":935,"href":936,"icon":937,"label":938},"Email","mailto:bhoov@gatech.edu","icons/email.svg","bhoov@gatech.edu",{"name":940,"href":941,"icon":942,"label":943},"CV","cv-pdfs/benjamin-hoover-cv.pdf","icons/pdf.svg","CV PDF",[945,947,948,949],{"name":904,"group":923,"href":905,"dataIcon":906,"label":904,"shortLabel":946},"Scholar",{"name":909,"group":923,"href":910,"dataIcon":911,"label":909},{"name":915,"group":923,"href":916,"faIcon":917,"dataIcon":918,"label":920,"shortLabel":920},{"name":922,"group":923,"href":924,"faIcon":925,"label":926,"shortLabel":926,"dataIcon":928},[951,957,962,968,974,986,993,999,1004,1010],{"title":952,"venues":953},"Hopfield Networks 2.0: Associative Memory for the Modern Era of AI",[954],{"location":955,"date":127,"locationUrl":956,"invited":167},"Plectics Lab Colloquium","https://www.youtube.com/watch?v=8LGRQfaG3ro",{"title":462,"venues":958},[959],{"location":960,"date":139,"locationUrl":961,"invited":167},"McMahon Lab at Cornell University","https://mcmahon.aep.cornell.edu/",{"title":963,"venues":964},"HAMUX: Inventing Hopfield Networks 2.0",[965],{"location":966,"date":967},"Georgia Tech CSE Hotseat","Nov 2022",{"title":969,"venues":970},"Comparing Language Models with LMDiff",[971],{"location":972,"date":973},"Demo at NeurIPS 2020","Dec 2020",{"title":975,"venues":976},"exBERT: Exploring Learned Embeddings in Transformer Models",[977,980,983],{"location":978,"date":979},"System Demonstration at ACL 2020","Jul 2020",{"location":981,"date":982},"IBM Exposition Demo at ICLR 2020","Apr 2020",{"location":984,"date":985},"System Demonstration at NeurIPS 2019","Dec 2019",{"title":987,"venues":988},"Unsupervised Attention Guided Atom Mapping with RXNMapper",[989,991],{"location":990,"date":979},"ML Interpretability for Scientific Discovery Workshop at ICML 2020",{"location":992,"date":979},"IBM Exposition Demo at ICML 2020",{"title":994,"venues":995},"Breaking the Wall of Black Box AI",[996],{"location":997,"date":998},"Falling Walls Lab Boston\"","Oct 2020",{"title":1000,"venues":1001},"The Inside Story",[1002],{"location":1003,"date":61,"invited":167},"MEng Graduation elected speaker",{"title":1005,"venues":1006},"Using Matlab's PRT to Accelerate Algorithm Development",[1007],{"location":1008,"date":1009,"invited":518},"Medtronic Diabetes R&D","Jul 2017",{"title":1011,"venues":1012},"The Impact of Encouragement",[1013],{"location":1014,"locationUrl":1015,"date":1016,"invited":167},"Cary Christian School Valedictorian Speech","https://myawesomeoliveshoots.com/2013/05/28/what-that-formerly-awkward-asian-guy-said-at-high-school-graduation-part-one/","May 2013",[1018,1028,1037,1043,1050,1057,1063],{"role":1019,"institution":94,"institutionUrl":1020,"location":49,"course":1021,"courseUrl":1022,"courseCode":1023,"instructors":1024,"date":1026,"description":1027},"Graduate Teaching Assistant","http://gatech.edu","Data and Visual Analytics","https://poloclub.github.io/cse6242-2023fall-online/","CS 6242",[103,1025],"Mahdi Roozbahani","Fall '23 - Spring '24","Organized project teams, graded projects, and held weekly office hours for an online graduate course with 947 students enrolled.",{"role":1019,"institution":59,"institutionUrl":1029,"location":60,"course":1030,"courseUrl":1031,"courseCode":1032,"instructors":1033,"date":1035,"description":1036},"http://duke.edu","Pattern Recognition Technology","https://www.coursicle.com/duke/courses/ECE/681/","ECE 681",[1034],"Patrick Wang","Spring '18","Designed homeworks, supervised projects, and occasionally teach lectures.",{"role":1019,"institution":59,"location":60,"course":1038,"courseCode":1039,"instructors":1040,"date":1035,"description":1042},"Biopotential Amplifier Design","BME 590",[1041],"Jonathan Viventi","Supervised and graded capstone projects where students designed and assembled 2-channel EEG readers",{"role":1019,"institution":59,"location":60,"course":1044,"courseCode":1045,"instructors":1046,"date":1035,"description":1049},"Fundamentals of Data Analysis and Decision Science","EGR 190L",[1047,1048],"Stacy Tantum","Paul Bendich","As a TA, I helped setup class infrastructure (Python, jupyter) and initial curriculum  for this 25 student pilot course for \u003Ca href=\"https://bigdata.duke.edu/data\">Duke's Data+ Program.\u003C/a>",{"role":1051,"institution":59,"location":60,"course":1052,"courseCode":1053,"instructors":1054,"date":1055,"description":1056},"Undergraduate Teaching Assistant","Introduction to Medical Instrumentation","BME 354L",[1041],"Spring '17","Prepared, supervised, and graded labs where students designed medical devices  such as Ultrasound, ECGs, Baby Incubators, and functional FitBits.",{"role":1051,"institution":59,"location":60,"course":1058,"courseCode":1059,"instructors":1060,"date":1061,"description":1062},"Introduction to Electrical Circuits","ECE 110",[1047],"Jan '15 - May '18","Graded homeworks, held weekly office hours, supervised labs, and private tutored students.",{"role":1064,"institution":59,"date":1065,"location":60,"instructors":1066,"description":1068},"Boeing Fellow","Jan '16 - May '17",[1067],"Carmen Rawls","Wrote STEM lesson plans to engage middle and high school students in the Durham area."],"uses":{}},null]}
